import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
import os
import time
import random
import argparse # å¼•å…¥ argparse è™•ç†åƒæ•¸
import json     # å¼•å…¥ json å„²å­˜çµæœ
import numpy as np
from sklearn.metrics import roc_auc_score, accuracy_score # å¼•å…¥ AUC è¨ˆç®—

from model import MultiModalDetector
from dataloader import init_dataloaders 

# ============================================================
# è¨“ç·´è¨­å®š
# ============================================================
NUM_EPOCHS = 20
LEARNING_RATE = 1e-4
# L2 æ­£å‰‡åŒ–å¼·åº¦ (Weight Decay)
WEIGHT_DECAY = 1e-4 # <--- å¼•å…¥ L2 æ­£å‰‡åŒ–ç­–ç•¥
# æ—©æœŸåœæ­¢åƒæ•¸
PATIENCE = 5 # <--- é€£çºŒ 5 å€‹ epoch æ€§èƒ½æœªæ”¹å–„å‰‡åœæ­¢
MODAL_DROPOUT_RATE = 0.2 # <--- æ¨¡æ…‹ Dropout æ¦‚ç‡ (éš¨æ©Ÿç¦ç”¨ä¸€å€‹æ¨¡æ…‹)

DEVICE = torch.device("cuda:1" if torch.cuda.is_available() else "cuda:0")
# DEVICE = torch.device("cpu")
CHECKPOINT_DIR = 'checkpoints'
os.makedirs(CHECKPOINT_DIR, exist_ok=True)


# ============================================================
# è¨“ç·´å‡½æ•¸ (ä¿æŒä¸è®Šï¼Œå› ç‚ºè¨“ç·´æ™‚ä¸éœ€è¦è¨ˆç®— AUC)
# ============================================================
def train_epoch(model, dataloader, criterion, optimizer, epoch, writer, modality_mode):
    model.train()
    total_loss = 0.0
    
    pbar = tqdm(dataloader, desc=f"Epoch {epoch} [Train]", unit="batch")
    
    for I_rgb, I_rppg, labels in pbar:
        I_rgb = I_rgb.to(DEVICE)
        I_rppg = I_rppg.to(DEVICE)
        labels = labels.to(DEVICE).unsqueeze(1)

        optimizer.zero_grad()

        # --- æ‡‰ç”¨æ¨¡æ…‹ Dropout (åƒ…åœ¨ multi_modal æ¨¡å¼ä¸‹) ---
        input_rgb = I_rgb
        input_rppg = I_rppg
        
        if modality_mode == 'multi_modal' and random.random() < MODAL_DROPOUT_RATE:
            # éš¨æ©Ÿç¦ç”¨ä¸€å€‹æ¨¡æ…‹
            if random.random() < 0.5:
                # ç¦ç”¨ RGB
                input_rgb = I_rgb.new_zeros(I_rgb.shape)
            else:
                # ç¦ç”¨ rPPG
                input_rppg = I_rppg.new_zeros(I_rppg.shape)


        # æ ¹æ“šæ¨¡æ…‹æ¨¡å¼é¸æ“‡è¼¸å…¥
        if modality_mode == 'rgb_only':
            outputs = model(I_rgb, I_rgb.new_zeros(I_rppg.shape)) # å‚³å…¥é›¶å¼µé‡ç¦ç”¨ rPPG è·¯å¾‘
        elif modality_mode == 'rppg_only':
            outputs = model(I_rgb.new_zeros(I_rgb.shape), I_rppg) # å‚³å…¥é›¶å¼µé‡ç¦ç”¨ RGB è·¯å¾‘
        else: # multi_modal
            outputs = model(I_rgb, I_rppg)
        
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        pbar.set_postfix({'Loss': f'{loss.item():.4f}'})

    avg_loss = total_loss / len(dataloader)
    writer.add_scalar('Loss/Train', avg_loss, epoch)
    print(f"Epoch {epoch} Train Loss: {avg_loss:.4f}")
    
    return avg_loss

# ============================================================
# é©—è­‰å‡½æ•¸ (æ–°å¢ AUC è¨ˆç®—èˆ‡æ¨¡æ…‹åˆ‡æ›)
# ============================================================
def validate_epoch(model, dataloader, criterion, epoch, writer, modality_mode, set_name):
    model.eval()
    total_loss = 0.0
    
    all_labels = []
    all_scores = []
    
    pbar = tqdm(dataloader, desc=f"Epoch {epoch} [{set_name}]", unit="batch")
    
    with torch.no_grad():
        for I_rgb, I_rppg, labels in pbar:
            I_rgb = I_rgb.to(DEVICE)
            I_rppg = I_rppg.to(DEVICE)
            labels = labels.to(DEVICE).unsqueeze(1)

            # æ ¹æ“šæ¨¡æ…‹æ¨¡å¼é¸æ“‡è¼¸å…¥
            if modality_mode == 'rgb_only':
                outputs = model(I_rgb, I_rgb.new_zeros(I_rppg.shape))
            elif modality_mode == 'rppg_only':
                outputs = model(I_rgb.new_zeros(I_rgb.shape), I_rppg)
            else: # multi_modal
                outputs = model(I_rgb, I_rppg)
                
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            
            # å°‡ logits è½‰æ›ç‚ºæ¦‚ç‡åˆ†æ•¸
            scores = torch.sigmoid(outputs).cpu().numpy()
            
            all_labels.extend(labels.cpu().numpy())
            all_scores.extend(scores)
            
            pbar.set_postfix({'Loss': f'{loss.item():.4f}'})

    # è¨ˆç®—æœ€çµ‚æŒ‡æ¨™
    avg_loss = total_loss / len(dataloader)
    all_labels = np.array(all_labels)
    all_scores = np.array(all_scores)
    
    # é æ¸¬é¡åˆ¥ (é–¾å€¼ 0.5)
    all_preds = (all_scores > 0.5).astype(int) 
    
    # è¨ˆç®— AUC
    auc_score = roc_auc_score(all_labels, all_scores)
    
    # è¨ˆç®— Accuracy
    accuracy = accuracy_score(all_labels, all_preds)

    # TensorBoard å¯è¦–åŒ–
    writer.add_scalar(f'Loss/{set_name}', avg_loss, epoch)
    writer.add_scalar(f'Accuracy/{set_name}', accuracy, epoch)
    writer.add_scalar(f'AUC/{set_name}', auc_score, epoch)
    
    print(f"Epoch {epoch} {set_name} Loss: {avg_loss:.4f}, Acc: {accuracy:.4f}, AUC: {auc_score:.4f}")
    
    return avg_loss, accuracy, auc_score

# ============================================================
# ä¸»ç¨‹å¼ (æ–°å¢åƒæ•¸è§£æ)
# ============================================================
def main(modality_mode, train_mode): # main å‡½æ•¸ç¾åœ¨æ¥æ”¶å…©å€‹æ¨¡å¼åƒæ•¸
    # è¨­å®š TensorBoard æ—¥èªŒç›®éŒ„åç¨±ï¼ŒåŒ…å«å…©ç¨®æ¨¡å¼å’Œæ™‚é–“æˆ³è¨˜
    log_time = time.strftime("%Y%m%d-%H%M%S")
    global LOG_DIR, WRITER
    
    # è¨­ç½® LOG_DIRï¼šä¾‹å¦‚ runs/multi_modal_cross_generator_20251129-215000
    LOG_DIR = f'runs/stage3/{modality_mode}_{train_mode}_{log_time}'
    WRITER = SummaryWriter(LOG_DIR)
    
    # --- 1. åˆå§‹åŒ– DataLoader ---
    global train_loader, val_loader
    train_loader, val_loader = init_dataloaders(train_mode)
    
    # 2. åˆå§‹åŒ–æ¨¡å‹ (ä¿æŒä¸è®Š)
    model = MultiModalDetector(num_classes=1)    # æ ¹æ“šæ¨¡æ…‹æ¨¡å¼å‡çµä¸ä½¿ç”¨çš„åˆ†æ”¯ (å¯é¸ï¼Œä½†æ›´åš´è¬¹)
    if modality_mode == 'rgb_only':
        print("æ¨¡å¼: åƒ…ä½¿ç”¨ RGBã€‚å‡çµ rPPG ç›¸é—œåƒæ•¸ã€‚")
        for param in model.E_rppg.parameters():
            param.requires_grad = False
    elif modality_mode == 'rppg_only':
        print("æ¨¡å¼: åƒ…ä½¿ç”¨ rPPGã€‚å‡çµ RGB ç›¸é—œåƒæ•¸ã€‚")
        for param in model.E_rgb.parameters():
            param.requires_grad = False
    
    model.to(DEVICE)
    
    # 2. å®šç¾©æå¤±å‡½æ•¸å’Œå„ªåŒ–å™¨
    criterion = nn.BCEWithLogitsLoss() 
    
    # å„ªåŒ–å™¨åªæ›´æ–° requires_grad=True çš„åƒæ•¸
    # è³¦äºˆ Adam å„ªåŒ–å™¨ Weight Decay åƒæ•¸
    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), 
                           lr=LEARNING_RATE,
                           weight_decay=WEIGHT_DECAY) # <--- L2 æ­£å‰‡åŒ–æ‡‰ç”¨ 
       
    best_val_auc = 0.0
    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_auc': []}
    
    # æ—©æœŸåœæ­¢è¨ˆæ•¸å™¨
    epochs_no_improve = 0

    print(f"Starting training for mode: {modality_mode} on device: {DEVICE}")
    
    # 3. è¨“ç·´å¾ªç’°
    for epoch in range(1, NUM_EPOCHS + 1):
        # è¨“ç·´éšæ®µ
        train_loss = train_epoch(model, train_loader, criterion, optimizer, epoch, WRITER, modality_mode)
        
        # é©—è­‰éšæ®µ
        val_loss, val_acc, val_auc = validate_epoch(model, val_loader, criterion, epoch, WRITER, modality_mode, 'Validation')
        
        # 5. æ—©æœŸåœæ­¢æª¢æŸ¥
        if val_auc > best_val_auc:
            best_val_auc = val_auc
            epochs_no_improve = 0 # é‡ç½®è¨ˆæ•¸å™¨
            
            # å„²å­˜æ¨¡å‹ (è·¯å¾‘ä¸­åŠ å…¥ mode å’Œ log_time)
            checkpoint_path = os.path.join(CHECKPOINT_DIR, f'{modality_mode}_{train_mode}_best_model_{log_time}.pth')
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_auc': best_val_auc,
            }, checkpoint_path)
            print(f"Checkpoint saved to {checkpoint_path} (Best Val AUC: {best_val_auc:.4f})")
        else:
            epochs_no_improve += 1
            print(f"No improvement in Val AUC. Counter: {epochs_no_improve}/{PATIENCE}")
            
        if epochs_no_improve == PATIENCE:
            print(f"--- ğŸ›‘ Early stopping triggered after {PATIENCE} epochs without improvement. ---")
            break # è·³å‡ºè¨“ç·´å¾ªç’°


        # 4. å„²å­˜è¨“ç·´æ­·å²
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)
        history['val_auc'].append(val_auc)
        
        # 5. å„²å­˜æ¨¡å‹ (æ ¹æ“š AUC)
        if val_auc > best_val_auc:
            best_val_auc = val_auc
            checkpoint_path = os.path.join(CHECKPOINT_DIR, f'{modality_mode}_best_model.pth')
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_auc': best_val_auc,
            }, checkpoint_path)
            print(f"Checkpoint saved to {checkpoint_path} (Best Val AUC: {best_val_auc:.4f})")

        print("-" * 50)

    WRITER.close()
    print("Training finished.")
    
    # 6. å°‡è¨“ç·´æ­·å²å„²å­˜åˆ°æª”æ¡ˆ
    history_file = os.path.join(CHECKPOINT_DIR, f'{modality_mode}_training_history.json')
    with open(history_file, 'w') as f:
        json.dump(history, f)
    print(f"Training history saved to {history_file}")


# ============================================================
# åŸ·è¡Œå™¨ (ä½¿ç”¨ argparse è™•ç†åƒæ•¸åˆ‡æ›)
# ============================================================
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Multi-Modal Deepfake Detector Training")
    
    # æ¨¡æ…‹æ¨¡å¼ (å·²å­˜åœ¨)
    parser.add_argument('--mode', type=str, default='rppg_only', 
                        choices=['rgb_only', 'rppg_only', 'multi_modal'],
                        help="é¸æ“‡é‹è¡Œçš„æ¨¡æ…‹: rgb_only, rppg_only, æˆ– multi_modal")
    
    # è³‡æ–™é›†éæ¿¾æ¨¡å¼ (æ–°å¢)
    parser.add_argument('--train_mode', type=str, default='unrestricted',
                        choices=['unrestricted', 'cross_generator'],
                        help="è³‡æ–™é›†éæ¿¾æ¨¡å¼: unrestricted (æ‰€æœ‰æ•¸æ“š), cross_generator (Train: Deepfakes, Val/Test: FaceSwap)")
    
    args = parser.parse_args()
    
    # å‚³éå…©å€‹åƒæ•¸çµ¦ main å‡½æ•¸
    main(args.mode, args.train_mode)

# python /ssd1/bkchen/MMIP/scripts/model/train.py --mode rppg_only --train_mode cross_generator